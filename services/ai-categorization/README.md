# ü§ñ AI-Kategorisierung Service

Lokaler Service zur automatischen Kategorisierung von Inquiry-Eintr√§gen mit Ollama.

## üìã √úbersicht

Dieser Service verwendet Ollama (lokale LLM) um Kundenanfragen automatisch zu kategorisieren:
- **Betreff** + **Nachricht** ‚Üí **Kategorie**
- Kategorien: `general`, `technical`, `billing`, `feedback`, `other`

## üöÄ Schnellstart

### 1. Ollama installieren

**Windows:**
1. Download von https://ollama.com/download
2. Installiere Ollama (wird als Service gestartet)
3. √ñffne PowerShell und lade Modell:
   ```powershell
   ollama pull llama3.2:3b
   ```

**Pr√ºfe Installation:**
```powershell
ollama list
```

Du solltest `llama3.2:3b` in der Liste sehen.

### 2. AI-Service starten

```powershell
cd services\ai-categorization
powershell -ExecutionPolicy Bypass -File .\start.ps1
```

Der Service:
- Erstellt automatisch Virtual Environment
- Installiert Dependencies
- Startet auf Port 9001

### 3. Testen

**Health Check:**
```powershell
curl http://localhost:9001/healthz
```

**Kategorisierung testen:**
```powershell
curl -X POST http://localhost:9001/categorize -H "Content-Type: application/json" -d "{\"subject\":\"Rechnung\",\"message\":\"Ich habe eine Frage zu meiner letzten Rechnung\"}"
```

Erwartete Antwort:
```json
{
  "category": "billing",
  "confidence": 0.85,
  "reasoning": "Kategorisiert als 'billing' basierend auf Inhalt"
}
```

## üì° API-Endpunkte

### POST `/categorize`

Kategorisiert eine Anfrage.

**Request:**
```json
{
  "subject": "Technisches Problem",
  "message": "Meine App st√ºrzt st√§ndig ab",
  "user_id": "optional-user-id"
}
```

**Response:**
```json
{
  "category": "technical",
  "confidence": 0.85,
  "reasoning": "Kategorisiert als 'technical' basierend auf Inhalt"
}
```

### GET `/healthz`

Pr√ºft ob Service und Ollama verf√ºgbar sind.

**Response:**
```json
{
  "status": "ok",
  "model": "llama3.2:3b",
  "ollama_available": true
}
```

### GET `/categories`

Gibt verf√ºgbare Kategorien zur√ºck.

**Response:**
```json
{
  "categories": {
    "general": "Allgemeine Anfragen",
    "technical": "Technische Probleme oder Support",
    "billing": "Rechnungen, Zahlungen, Preise",
    "feedback": "Feedback, Vorschl√§ge, Bewertungen",
    "other": "Sonstige Anfragen"
  }
}
```

## ‚öôÔ∏è Konfiguration

In `start.ps1` anpassen:

```powershell
$env:OLLAMA_MODEL = "llama3.2:3b"  # Oder anderes Modell
$env:AI_SERVICE_PORT = "9001"      # Port √§ndern
```

### Empfohlene Modelle

| Modell | Gr√∂√üe | Geschwindigkeit | Qualit√§t | Empfehlung |
|--------|-------|-----------------|----------|------------|
| `llama3.2:3b` | ~2GB | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | **Empfohlen** |
| `mistral:7b` | ~4GB | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | Bessere Qualit√§t |
| `llama3.2:1b` | ~1GB | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê | Sehr schnell |

## üîß Troubleshooting

### "Ollama not available"

Pr√ºfe ob Ollama l√§uft:
```powershell
ollama list
```

Falls nicht, starte Ollama neu oder installiere es von https://ollama.com

### "Model not found"

Lade das Modell:
```powershell
ollama pull llama3.2:3b
```

### "Port 9001 already in use"

√Ñndere Port in `start.ps1` oder beende anderen Prozess:
```powershell
netstat -ano | findstr :9001
taskkill /PID <PID> /F
```

### Service startet nicht

1. Pr√ºfe Python Installation: `py --version`
2. Pr√ºfe Virtual Environment: `ls .venv`
3. Installiere Dependencies manuell:
   ```powershell
   .\.venv\Scripts\Activate.ps1
   pip install -r requirements.txt
   ```

## üîÑ Integration mit Supabase

Der Service wird von der Supabase Edge Function aufgerufen:

```
Neuer Inquiry ‚Üí Trigger ‚Üí Edge Function ‚Üí AI-Service (Port 9001) ‚Üí Update ai_category
```

**Wichtig:** F√ºr lokale Tests muss die Edge Function mit Supabase CLI lokal laufen!

## üìä Beispiele

### Technische Anfrage
```json
{
  "subject": "App st√ºrzt ab",
  "message": "Die App friert ein wenn ich auf Speichern klicke"
}
‚Üí "technical"
```

### Rechnungsanfrage
```json
{
  "subject": "Rechnung",
  "message": "Ich habe die Rechnung noch nicht erhalten"
}
‚Üí "billing"
```

### Feedback
```json
{
  "subject": "Verbesserungsvorschlag",
  "message": "Es w√§re toll wenn man Farben anpassen k√∂nnte"
}
‚Üí "feedback"
```

## üéØ Features

- ‚úÖ **100% lokal** - Keine Cloud, keine API-Kosten
- ‚úÖ **Schnell** - Kategorisierung in 1-2 Sekunden
- ‚úÖ **Privat** - Daten verlassen nie deinen Computer
- ‚úÖ **Offline** - Funktioniert ohne Internet
- ‚úÖ **Anpassbar** - Kategorien und Prompts einfach √§nderbar

---

**Made with ‚ù§Ô∏è using Ollama**
